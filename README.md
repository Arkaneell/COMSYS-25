# COMSYS-2025 - The 6th International Conference on Frontiers in Computing and Systems (COMSYS-2025)
# Theme: Robust Face Recognition and Gender Classification under Adverse Visual Conditions

## Task A: RCG-Net - ResNet50-Based Gender Classification Network
RCG-Net presents a sophisticated deep learning architecture for binary gender classification from facial images, leveraging transfer learning principles with advanced attention mechanisms. The model employs ResNet50 as its backbone network, pre-trained on ImageNet with frozen weights to serve as a robust feature extractor for 224×224×3 RGB input images. The architecture is enhanced with two complementary attention mechanisms: a Squeeze-and-Excitation (SE) block that performs channel-wise attention with a reduction ratio of 16, and a Convolutional Block Attention Module (CBAM) that combines both channel and spatial attention using 7×7 convolutions with global average and max pooling operations.
The network architecture follows a sequential flow: input images are processed through the frozen ResNet50 backbone, followed by a 64-filter convolutional layer with ReLU activation, then the SE block for channel attention, CBAM for dual attention, another 32-filter convolutional layer, global average pooling, a 64-unit dense layer with dropout regularization (0.4), and finally a single-unit sigmoid output layer for binary classification. The model is trained using the Adam optimizer with binary cross-entropy loss over 100 epochs with a batch size of 16, where labels are encoded as 0 for female and 1 for male classifications.
Data preprocessing follows ResNet50 specifications with mean centering and scaling, while comprehensive evaluation includes confusion matrix analysis, classification reports with precision/recall/F1-score metrics, and training curve visualization. The dual attention mechanism significantly enhances feature selection by emphasizing important channels through SE blocks while simultaneously focusing on relevant spatial regions via CBAM, resulting in improved classification accuracy. This architecture demonstrates the effectiveness of combining established CNN backbones with modern attention mechanisms for robust gender classification tasks in computer vision applications.
### Architecture Flow Diagram
```
Input (224×224×3) → ResNet50 (Frozen) → Conv2D(64) → SE Block → CBAM → Conv2D(32) → GAP → Dense(64) → Dropout(0.4) → Dense(1, Sigmoid) → Gender Prediction
```
![image](https://github.com/user-attachments/assets/21127d7e-146b-470c-b91e-5fea95654063)


## Task B: TRF-Net: Triplet ResNet Fusion Network for Robust Face Recognition

**TRF-Net** is a deep learning architecture designed for robust face recognition that combines transfer learning, attention mechanisms, and triplet loss optimization to handle challenging scenarios including distorted and degraded facial images. The network leverages a pre-trained ResNet50 backbone as a feature extractor, followed by custom convolutional layers enhanced with Squeeze-and-Excitation (SE) blocks and Convolutional Block Attention Module (CBAM) for improved feature representation. The SE blocks perform channel-wise attention by learning channel relationships through global average pooling and fully connected layers, while CBAM provides both channel and spatial attention mechanisms to focus on discriminative facial features. The network outputs 128-dimensional L2-normalized embeddings that capture essential facial characteristics in a compact representation.

The training methodology employs triplet loss with a margin of 0.2, where each training sample consists of an anchor image (clean face), a positive image (distorted version of the same person), and a negative image (different person). This approach enables the network to learn robust embeddings that minimize intra-class distance while maximizing inter-class separation. The triplet generation strategy specifically pairs clean facial images with their corresponding distorted variants (including rainy, blurry, or other degradations) as positive samples, ensuring the model learns invariance to common image distortions. The network processes 224×224 RGB images normalized to [0,1] range and uses Adam optimizer with custom accuracy metrics that measure the proportion of triplets where the anchor-positive distance is smaller than the anchor-negative distance.

For inference, TRF-Net computes embeddings for query faces and matches them against a reference database using cosine similarity. The system achieves face recognition by identifying the closest match above a predefined threshold, with the ability to reject unknown faces when similarity scores fall below the threshold. The network's architecture enables efficient processing of large-scale datasets while maintaining high accuracy on both clean and distorted facial images, making it particularly suitable for real-world applications where image quality may be compromised due to environmental factors or acquisition conditions.

![image](https://github.com/user-attachments/assets/886181f4-504a-4843-b90e-c09903cc004a)
